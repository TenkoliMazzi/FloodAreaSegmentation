{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceCELoss, DiceLoss\n",
    "from monai.data import Dataset\n",
    "from monai.transforms import Compose,ToTensord, LoadImaged, EnsureChannelFirstD, Rotate90d, Flipd, ToDeviced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloodAreaSegmentation(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.lenght = len(data)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.lenght\n",
    "\n",
    "    def __getitem__(self, index):       \n",
    "        return {'image': self.data[index][\"image\"] , 'label': self.data[index][\"label\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader() :\n",
    "    def __init__(self, dataset, batch_size=5, shuffle=True, transform = None, sides_size = 512, device = torch.device(\"cpu\")) :\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "        self.size = sides_size\n",
    "        self.shuffle = True\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.aviable_indexes = list(range(self.dataset.lenght))\n",
    "        return self        \n",
    "\n",
    "    def __next__(self):\n",
    "        actual_batch_size = self.batch_size if len(self.aviable_indexes) >= self.batch_size else len(self.aviable_indexes)\n",
    "        if actual_batch_size <= 0 :\n",
    "            raise StopIteration() \n",
    "        if self.shuffle :\n",
    "            sampled_elements = random.sample(self.aviable_indexes, actual_batch_size)\n",
    "        else :\n",
    "            sampled_elements = self.aviable_indexes[:actual_batch_size]\n",
    "        \n",
    "        batch_images = torch.zeros((self.batch_size,3,self.size,self.size)).to(self.device)\n",
    "        batch_labels = torch.zeros((self.batch_size,1,self.size,self.size)).to(self.device)\n",
    "        batch = {}\n",
    "        batch[\"image\"] = batch_images\n",
    "        batch[\"label\"] = batch_labels\n",
    "        for i,element in enumerate(sampled_elements):                \n",
    "            to_select = self.aviable_indexes.index(element)\n",
    "            transformed =  self.transform({\"image\" : self.dataset[to_select][\"image\"],\"label\" :self.dataset[to_select][\"label\"]})\n",
    "            batch[\"image\"][i] = transformed[\"image\"]     \n",
    "            batch[\"label\"][i] = transformed[\"label\"]\n",
    "            batch[\"label\"][i]  = torch.where(batch[\"label\"][i] == 255, 1,0)\n",
    "            self.aviable_indexes.remove(element)\n",
    "        return batch\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path, labels_path = tuple([f\"Dataset/Train/{x}\" for x in [\"Images\",\"Labels\"]])\n",
    "\n",
    "train_set = {num : {\n",
    "    \"image\" : f\"{images_path}/{num}.png\",\n",
    "    \"label\" : f\"{labels_path}/{num}.png\"   \n",
    "} for num in range(0,699)}\n",
    "\n",
    "images_path, labels_path = tuple([f\"Dataset/Test/{x}\" for x in [\"Images\",\"Labels\"]])\n",
    "\n",
    "test_set = {num - 700 : {\n",
    "    \"image\" : f\"{images_path}/{num}.png\",\n",
    "    \"label\" : f\"{labels_path}/{num}.png\"   \n",
    "} for num in range(700,1045)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(\n",
    "spatial_dims=2, \n",
    "in_channels=3, \n",
    "out_channels=1,\n",
    "channels=(16,32,64,128,256,512),\n",
    "strides=(2,2,2,2,2),\n",
    "    num_res_units=4).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('unet_model_monai_dice.pth'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=['image','label']),\n",
    "    ToTensord(keys=['image','label']),\n",
    "    ToDeviced(keys=['image','label'],device=device),\n",
    "    EnsureChannelFirstD(keys=['image','label']),\n",
    "    Rotate90d(keys=['image','label'], k=3),\n",
    "    Flipd(keys=['image','label'], spatial_axis=1),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = FloodAreaSegmentation(train_set, transform=train_transforms)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=75, shuffle=True, transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicemetric(y_pred,y) :\n",
    "    overlap = torch.where(y_pred == y,1,0)\n",
    "    true_positives = torch.count_nonzero(torch.where(y == 1, overlap, 0))\n",
    "    false_negatives = torch.count_nonzero(torch.where(y == 1, 1 - overlap, 0))\n",
    "    false_positive = torch.count_nonzero(torch.where(y==0, 1 - overlap, 0))\n",
    "    return 2*true_positives/(false_negatives+false_positive + 2*true_positives)\n",
    "    \n",
    "metrics = [\n",
    "    {\"name\" : \"dice\", \"function\" : dicemetric}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainloop(model,criterion,dataloader,quiet = False, flush_memory=False) :\n",
    "    model.train()    \n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch in dataloader:\n",
    "        step += 1\n",
    "\n",
    "        inputs, targets = batch['image'].to(device), batch['label'].to(device)        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        epoch_loss += loss.item()        \n",
    "        if(not quiet) : print(\"CE:{}\".format(loss.item()))  \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "    if flush_memory : torch.cuda.empty_cache()\n",
    "\n",
    "    return epoch_loss/step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, metrics, dataloader : DataLoader, quiet = True) :    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    step = 0    \n",
    "    for batch in dataloader :    \n",
    "        step +=1\n",
    "        inputs, targets = batch['image'].to(device), batch['label'].to(device)\n",
    "        outputs = model(inputs)   \n",
    "        for metric in metrics :            \n",
    "            metric_name = metric[\"name\"]\n",
    "            criterion = metric[\"function\"]\n",
    "            loss = criterion(outputs, targets)\n",
    "            if(not quiet) : print(f\"{metric_name} : {loss.item()}\")\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    metric_scores = []\n",
    "    for metric in metrics :\n",
    "        metric_name = metric[\"name\"]\n",
    "        if(not quiet) : print(f\"Final-{metric_name} : {epoch_loss/step}\")\n",
    "        metric_scores.append({\"name\": metric_name, \"score\" : {epoch_loss/step} })\n",
    "\n",
    "    return metric_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "criterion = DiceCELoss(sigmoid=True).to(device)\n",
    "train_losses = []\n",
    "test_metrics = []\n",
    "     \n",
    "for epoch in range(num_epochs):   \n",
    "    loss = trainloop(model,criterion,dataloader_train)\n",
    "    train_losses.append(loss)\n",
    "    torch.cuda.empty_cache()\n",
    "    scores = test(model,metrics,dataloader_train)\n",
    "    test_metrics.append(scores)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]}')\n",
    "    for score in scores :\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, {score[\"name\"]} : {score[\"score\"]}')\n",
    "\n",
    "torch.save(model.state_dict(), 'unet_model_monai_dice.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def display_segmentation(model,dataset : FloodAreaSegmentation,id) :\n",
    "    input_dict = dataset.transform(dataset[id])    \n",
    "    model.eval()\n",
    "    img = torch.unsqueeze(input_dict[\"image\"],dim=0)\n",
    "    print(img.shape)\n",
    "    img_r = img[0,0,:,:]\n",
    "    img_g = img[0,1,:,:]\n",
    "    img_b = img[0,2,:,:]\n",
    "    img_rgb = torch.stack([img_r,img_g,img_b],dim=2).to(torch.int32)    \n",
    "\n",
    "    output = model(img)\n",
    "    # out_treshold = torch.where(output>0,1,0)\n",
    "    out_treshold = torch.sigmoid(output)\n",
    "\n",
    "    lab = (input_dict[\"label\"][0,:,:].cpu()).to(torch.int32)\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(lab)\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(img_rgb.detach().cpu())\n",
    "    plt.subplot(1,3,3)   \n",
    "    plt.imshow(out_treshold.detach().cpu()[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = FloodAreaSegmentation(test_set,transform=train_transforms)\n",
    "dataloader_test = DataLoader(dataset_test,25,transform=train_transforms,sides_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_segmentation(model,dataset_test,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model,metrics,dataloader_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
